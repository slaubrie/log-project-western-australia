---
title: "log-project-aubrie-winnie"
output:
  pdf_document: default
  html_document: default
date: "2024-02-01"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Understanding how spatial variation is linked to diversity maintenance in natural communities is a pillar of plant community ecology. Theoretically, a variable landscape can maintain diversity via niche partitioning: different species can trade off in performing better or worse depending on the conditions of the patch they are growing in, and as a result, more species can sustainably coexist in a community than if it were spatially heterogeneous. In the hyperdiverse system of native annual plants in Western Australia, fallen logs may be one of the greatest contributors to generating spatial variation that could help maintain species diversity. Considerable anecdotal evidence suggests that fallen logs generate spatial variation, or patchiness, in the environment (Figure 1), and that species or assemblages of plants may respond differently depending on if they are near logs or not. Despite such anecdotal evidence, it is yet unknown if and how fallen logs contribute to maintaining species diversity in the native annual plant communities of the Western Australian wheat belt. 

<center>
![Figure 1: image of annual plant halos around logs](example_winter.JPG){width=50%}
</center>
The project will address the following questions: 

**Q1) Are/how are plant communities in fallen log patches different from patches that are in the open?**

**Q2) Why are plant communities in fallen log patches different from patches in the open?** 

**Q3) Are/how are plant species performances affected by proximity to fallen logs?** 

### Hypotheses
The null hypothesis, H0, is that annual plants in fallen log patches are not different in diversity, abundance, or composition from open patches. 

In addition to the null hypothesis, the following constitute four, non-mutually exclusive hypotheses concerning how fallen logs may introduce spatial variation in the environment. I include corresponding predictions for how plant communities may differ between fallen log patches as compared to open patches.
<br><br>
**H1: Log decomposition creates islands of fertility directly around the fallen log.** <br>
Prediction 1: Nutrient composition around logs will be higher than in open plots <br>

Prediction 2: Variation in nutrient composition in log vs open environments will correspond to variation in species composition, abundance, and/or richness in these environments. <br>

Prediction 3: All sown plants will perform best in environments where organic logs have been left 'insitu'.  In locations where logs have been removed or replaced with pvc, the legacy of the nutrient island effect will yield higher sown plant performance than when compared to locations where logs have never been. The effect of the nutrient island in locations where logs have been added to open environments should yeild higher plant performance over time. *note: performance is measured in terms of germination rate, survival to fruiting, fecundity, and/or biomass.* <br><br>

**H2: Fallen logs alter the microclimate directly around them by providing shade.**<br> Prediction 1: Shade and temperature around logs vs in open plots will be different <br>

Prediction 2: Variation in shade and temperature in log vs open environments will correspond to variation in species composition, abundance, and/or richness in these environments. <br>

Prediction 3: All sown plants will perform best in environments where there are organic or pvc logs, no matter if they have been recently moved or not.<br><br>

**H3: Fallen logs trap dispersing seeds as they are blown along the ground.**<br>

Prediction 1: Dispersing seeds accumulate around logs, leading to a denser stand of plants in fallen log patches. Plant abundance in fallen log patches will be higher as compared to open patches. Rare plants will be more common in fallen log patches as compared to open patches <br>

Prediction 2: All sown plants will perform the same in all experimental environments <br><br>

**H4: At least some species perform differently according to variation in log vs. open environments and have short dispersal kernals, causing fitness-density covariance** <br><br>
<center>
![Figure 2: Photo before germination, after a rain. Notice the seeming wet halo under and around the branch](wetpatch_example2.jpg){width=50%}
</center><br>

### Experimental Design
In this experiment, 224 plots are arranged in 7 blocks of 32 plots each within the Caron Dam nature reserve. [A map can be found here](https://www.google.com/maps/d/edit?mid=1z6w6tScsCcKSpsdUmoupfOJVaaq16VYk&usp=sharing). <br>*note: the location info for 3.02 is probably incorrect as of May 2022, and location info is currently unavailable for plots 6.25 and 7.19* 

Each block is approximately 30m X 30m in area. Plots are 1m long and linear, and have a pin tag on either end (see Figure 3). The pin tags have the identity of the plot written on them in the form of "blocknumber.plotnumber". Plots are 1m or more away from each other. 

In each block, plot environments can be one of six types:<br>
-	A 1m log that is out in the open (open_with_log,  4 plots)  <br>
-	A 1m log that is a part of a tree (insitu_log, 4 plots)<br>
-	A 1m pvc pipe that is out in the open (open_with_pvc, 4 plots)<br>
-	A 1m pvc pipe that is a part of a tree (insitu_pvc, 4 plots)<br>
-	A plot that is out in the open (open, 8 plots) <br>
-	A gap in a log where a log used to be (gap, 8 plots)<br>

In half of the plots (not including open plots), the addition, exchange, or removal of logs or pvc to the environment was implemented in October 2020, before seed dispersal. In the other half of these plots, these manipulations were implemented after seed dispersal, in March 2021. 

Within each 1m long plot, there is a ~20cm long microtransect. The ends of the microtransects are marked by a nail and a washer sunken into the ground. Each microtransect is approximately 21 cm in internal length from inner washer edge to inner washer edge. Microtransects are not sided. 

In half of all plots, seeds were sown in March 2021 and February 2022. In these plots, 15 seeds each of Trachymene ornata (TROR), Goodenia rosea (GORO), and Trachymene cyanopetala (TRCY) are sown outside of the microtransects as in the diagram. These plants were selected because they represent plants common to communities next to logs (TROR), out in the open (GORO), or both (TRCY). The plots where seeds were sown are called 'lambda' plots as noted in Figure 3. In the dataset, the rows with a "1" in the 'seeding_trt' column are the plots that had seeds sown into them.

<center>
![Figure 3: plot schematic](plottypes2021.png){width=50%}
</center>

### Datasets 
The sets of data that we have collected for this arm of the project are the following. 

(1) Community data, before and after the experiment was implemented. <br> 
- Every year during peak biomass we surveyed plant communities at every centimeter along each microtransect. Plant count and identity information is collected at each centimeter. 
- These data are available from 2020 (before the experiment began), 2021 (one year into the experiment), and 2022 (two years into the experiment)

(2) Soil nutrient analysis in the open and insitu log plots.<br>
- These data were collected in 2023 

(3) Performance data of TROR, TRCY, and TROR. <br>
- In 2021, the only performance data that were collected after sowing the experiment were the **total number of plants that came up and survived to fruiting for each species in each location, their total biomass, and their per capita biomass**. I calculated per capita biomass by dividing total biomass of the collected focal plants by the number of focal plants observed. This was because of logistical issues due to covid. In this dataset, there were two instances where the number of plants collected was greater than the number of seeds sown. Both instances were T. cyanopetala, where nplants = 16 and 18. For these two datapoints I chose to convert the count values to 15, assuming that every individual we planted came up, and that the extra were either naturally occurring seeds or that the number of seeds that we put into the ground was greater than 15 (human error). To calculate total biomass for these two instances, I divided the total biomass by the number of individuals observed, and multiplied by 15. <br>

- In 2022, we went to the field early in the season and counted and thinned the number of germinated seedlings in each location. We therefore have a count for germination, but for the following reasons there are some issues with these data. The first is that we probably surveyed germination a little too early. The seedlings were often super small or hadn't come up yet. Because we couldn't come back later to re-thin the plots, we went ahead with counting and thinning seedlings. The values in the dataset for 2022 (nplants_data_2022.csv) corresponding to this germination survey are "ntrcy_germ", "ngoro_germ" and "ntror_germ". The second is that at the end of the growing season, Jake and Winnie came back and found that there was often more than one plant of the focal species where we seeded them, and sometimes there was one or more focal plants that popped up where we had not observed germination earlier in the season. We assume that these plants come from the seeds we planted, and that they came up later than our initial germination survey. The number of plants observed and collected at each location at the end of the season are in the columns "nplants_tror", "nplants_goro" and "nplants_trcy" in the nplants_data_2022.csv data file. Because ngerm and nplants don't totally capture what came up where we sowed seed, I chose to analyze the total number of observed plants. I calculated this as the number of total plants we observed between the germination and the end of the season, being careful not to double-count the individual that was left after thinning from the first round of germination survey. The performance data I analyze here are **total number of plants that came up for each species in each location, and the per capita biomass of plants collected at the end of the season**. 

## Methods and analysis

### **Q1 Are/how are plant communities in fallen log patches different from patches that are in the open?** <br>
#### *Overview of results* <br> 

#### *Statistical Methods* <br>

#### *Analysis*<br>

##### Abundance analysis
** 2020 - 2022 **
```{r, message=FALSE, warning=FALSE, include=TRUE, paged.print=FALSE, results=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# packages

require(vegan)
require(dplyr)
require(tidyr)
require(labdsv)
require(stringr)
require(ggplot2)
require(ggrepel)
require(lme4)
require(emmeans)
require(ggpubr)

##### data wrangling #####

# This dataset includes unknown species.
comm <- read.csv("20-22_species_composition_data_w_unk.csv", header=T)

# Remove the locations surveyed in 2021 and 2022 that were not surveyed in 2020 - aka, cm=0, cm=21, cm = 22, cm = 29.
comm<-comm[which(comm$cm_location!=21 & comm$cm_location!=0 & comm$cm_location!=22 & comm$cm_location!=29),]

# make a group name for each row
comm$grp<-apply(comm[c(1,3,5,6,7)], 1, paste, collapse=":") # timepoint, block, transect_name, initial state

# Need to make each row a community using matrify.
commsub<-comm[,c(15,10,13)] # group, species_code, and count of each species for each transect. transects are rows.
commsub <-as.data.frame(commsub)
commtry<-matrify(commsub) # make it an expanded species matrix 
commtry$x[which(is.na(commtry$x))] <- 1 # "x" means that there were no individuals in the transect, but we are going to keep track of this as if it were a species
ncol(commtry) # how many species are we working with in our community matrix

# Store grouping row names as a column, then remove rownames.
commtry$grps<-rownames(commtry)
rownames(commtry)<-NULL
names(commtry)

# Split group info into columns for each variable.
mat<-separate(commtry, 107, c("time","block","transect","init", "treatment"), ":")
names(mat) #check

# Add groupname using time, block, init columns.
mat$grp1<-apply(mat[c(107:110)], 1, paste, collapse=":")
mat$grp2<-apply(mat[c(107:111)], 1, paste, collapse=":")
names(mat) #check

# Another df where the grouping variables are time, block, transect and initial state.
# Each row is a transect in a certain year.
df<-mat[,c(1:106,113)]
# df2 = with treatment in the grouping
df2 = df %>% mutate(across(.cols=1:106,.fns=as.numeric))
rownames(df2)<-NULL # remove rownames

##### Abundance analysis for 2020 (t0) AND in-situ log and in-situ open plots in 2021 (t1) and 2022 (t2)

# Sum observations across initial X transect X time X  block X treatment (group variable).
# This gives number of plants in each row observation (transect level).
blocksum2<-rowsum(df2[,c(1:106)], group=df2$grp2)
blocksum2$grps<-rownames(blocksum2)
rownames(blocksum2)<-NULL # remove rownames

# Add in group vars.
nublock2<-separate(blocksum2, 107, c("time","block","transect","init", "treatment"), ":")
nublock2$total<-rowSums(nublock2[,c(1:106)])
nublock2$presence<-ifelse(nublock2$total > 0,  1, 0)

# Subset data where before treatments installed (t0), in-situ log and in-situ open from t1 and t2 are included.
# Hence only absolute log effect and absolute open effect are concerned
dat_t0_insitu<-nublock2[which(nublock2$time=="t0" |  nublock2$treatment=="open" |  nublock2$treatment=="insitu_log"),]

# look at plant abundance in log vs open 
# look at range of data - what family should i use? 
range(dat_t0_insitu$total)

# since samples from t1 and t2 from are mainly from the same plots as t0. These are not independent replicates and tend to correlated with each other.
# including year and block as random effects
# (1|year) + (1|block) as we think the effect of init on total is the same (slope) but the intercept differ amongst block and year
# but since we have a greater number of sample from t0, data from t0 will contribute more to the variance in abundance.
# see https://bookdown.org/steve_midway/DAR/random-effects.html#pld-example
abun.mod<- glmer(total~ init + (1|block) + (1|time), data=dat_t0_insitu, family = 'poisson')
summary(abun.mod)

emmeans(abun.mod, ~init, type='response') # plant abundance in log plots is higher by 0.04 plants - which is no higher

abun.plot <- emmip(abun.mod, ~init, type='response', CI=T)+theme_bw()+labs(x="Initial condition", y="Number of plants")
print(abun.plot)

##### Reason: why we need to include 'time' as random effect?

# (1) Samples from t1 and t2 from are from the same plots as t0. These are not independent replicates and tend to correlated with each other.
# We included year and block as random effects to alleviate the effect of temporal pseudo-replication.

summary(aov(total ~ time, data = dat_t0_insitu)) # plant abundance differs between years

# (2) When we stratify the data by year, significance of the difference between log and open treatment is lost.
# if the effect of log-open (slope) is the same across year, year only affecting the intercept.
# since the slopes are similar, we include time as random intercept effect.
summary(glm(total ~ init, data = subset(dat_t0_insitu, time == "t0"), family = poisson))
summary(glm(total ~ init, data = subset(dat_t0_insitu, time == "t1"), family = poisson))
summary(glm(total ~ init, data = subset(dat_t0_insitu, time == "t2"), family = poisson))

abun.plot.year <- ggplot(dat_t0_insitu, aes(x = as.factor(init), y = total, fill = as.factor(init))) +
  geom_boxplot(position = "dodge", alpha = 0.5) +
  labs(x = "init",
       y = "Abundance") +
  scale_fill_discrete(name = 'init') +
  theme_classic() +
  facet_grid(. ~ time) +
  stat_compare_means(comparisons = list(c("log", "open")), label = "p.format", method="wilcox.test")

print(abun.plot.year)
```

#### Diversity analysis
Main takeaways:

* we use a hurdle model to address zero-inflation
* we first use logistic regression to predict the probability of non-zero
* open and log environment significantly determines the probability of non-zero diversity index
* note, zero in Shannon diversity index does not mean zero plant. 
* we then use lmer to model non-zero diversity data with time and block as random terms
* we assume approximal Gaussian distribution (1) continuous variable and (2) visual inspection suggests so
```{r, message=FALSE, warning=FALSE, include=TRUE, paged.print=FALSE, results='markup', fig.width =8, fig.height=8}
require(vegan)
require(dplyr)
require(tidyr)
require(labdsv)
require(stringr)
require(ggplot2)
require(ggrepel)
require(lme4)
require(emmeans)
require(lmerTest)
require(performance)
require(ggpubr)
require(DHARMa)

# This dataset does not include unknown data.
comm <- read.csv("20-22_species_composition_data_no_unk.csv", header = T)

# Remove the locations surveyed in 2021 and 2022 that were not surveyed in 2020 - aka, cm=0, cm=21, cm = 22, cm = 29.
comm<-comm[which(comm$cm_location!=21 & comm$cm_location!=0 & comm$cm_location!=22 & comm$cm_location!=29),]

# make a group name for each row
comm$grp<-apply(comm[c(1,3,5,6,7)], 1, paste, collapse=":") # timepoint, block, transect_name, initial state

# Need to make each row a community using matrify
commsub<-comm[,c(15,10,13)] 

# group, species_code, and count of each species for each transect. transects are rows.
commsub <-as.data.frame(commsub)
commtry<-labdsv::matrify(commsub) # make it an expanded species matrix 
commtry$x[which(is.na(commtry$x))] <- 1  # "x" means that there were no individuals in the transect, but we are going to keep track of this as if it were a species
ncol(commtry) # how many species are we working with in our community matrix

# Store grouping row names as a column, then remove rownames.
commtry$grps<-rownames(commtry)
rownames(commtry)<-NULL
names(commtry)

# Split group info into columns for each variable
mat<-separate(commtry, 88, c("time","block","transect","init","treatment"), ":")
names(mat) #check

# Add groupname using time, block, init columns
mat$grp<-apply(mat[c(88:92)], 1, paste, collapse=":")
names(mat) #check

# Another df where the grouping variables are time, block, transect and initial state.
# Each row is a transect in a certain year.
df<-mat[,c(1:87,93)]
df2 = df %>% mutate(across(.cols=1:87,.fns=as.numeric)) # make everything numeric
rownames(df2)<-NULL # remove rownames

###### Species diversity analysis for 2020 - 2022 data (Shannon diversity on transect level) 
numat = mat %>% mutate(across(.cols=1:87,.fns=as.numeric)) # make everything numeric

# sum species for each group (grouped by init, transect, block, time)
nudat<-numat%>% 
  group_by(time, block, transect, init, treatment) %>% summarise(across(where(is.numeric), sum))

# make a data frame
dat<-as.data.frame(nudat) # this df contains transect levels from all years
dat<-dat[which(dat$time=="t0" |  dat$treatment=="open" |  dat$treatment=="insitu_log"),]

#estimate diversity for each row/group. don't include 'x' 

# no groups, just estimate diversity of each row
est<-dat[,c(6:91)]
dat$diversity<-diversity(est, index='shannon') 

###### We used a hurdle model since the data is zero-inflated
# separate into zero and non-zero observations
dat$non_zero <- ifelse(dat$diversity > 0, 1, 0)

# what does our data look like? 
hist(dat$diversity, xlab = "Shannon diversity", main = "Histogram of Shannon diversity index (all years, transect level)") # zero-inflated

ggplot(dat, aes(x = diversity, fill = as.factor(non_zero))) +
  geom_histogram(position = "identity", alpha = 1, bins = 30) +
  labs(x = "Diversity",
       y = "Frequency") +
  scale_fill_discrete(name = 'non_zero') +
  theme_bw()

shapiro.test((dat$diversity[dat$non_zero == 1])) # non-zero data is not normal

# Non-zero data is, however, an approximal Gaussian distribution
hist(dat$diversity[dat$non_zero ==1], xlab = "Shannon diversity index (non-zero)", main = "Histogram of Shannon diversity index (non-zero, all years, transect level)") # visually it resembles a lot like a Gaussian distribution 

# Gaussian distribution produced the best-fitting ggplot
dat_nonzerodat <- dat[dat$non_zero == 1, ]
ggplot(dat_nonzerodat, aes(sample = diversity)) + 
                  geom_qq(distribution = qnorm) + 
                  geom_qq_line(distribution = qnorm) +
                  ggtitle("normal")

# Hurdle model part 1. Logistic regression to predict the probability of non-zero.
# Ppen and log environment does determine the probability of non-zero diversity index
# 0 Shannon diversity index =/= zero plants
Hurd.mod.1 <- glmer(non_zero ~ init + (1|block) + (1|time), data = dat, family = binomial)
summary(Hurd.mod.1) # significant

# Hurdle model part 1. Linear mixed effect model to predict the mean of the non-zero data.
# We included block and time as random terms.
# Open and log environment is significant in explaining the plant diversity in transect levels.
# Lmer was used because the distribution of non-zero data is approximally normal.
Hurd.mod.2 <- lmer(diversity ~ init + (1|block)+ (1|time), data=subset(dat, non_zero == 1))
summary(Hurd.mod.2)
anova(Hurd.mod.2) # lmer on non-zero diversity values is significant

# Check residual
residuals <- resid(Hurd.mod.2) # Extract residuals
plot(residuals)
abline(0,0)
check_model(Hurd.mod.2)
```

#### Composition analysis
```{r, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE, results='markup', fig.width =8, fig.height=8}
# packages
library(tidyverse)
require(vegan)
require(dplyr)
require(tidyr)
require(labdsv)
require(stringr)
require(ggplot2)
require(ggrepel)
require(lme4)
require(emmeans)
require(lmerTest)
require(performance)
require(ggpubr)

# Data wrangling
# This data set does not include unknown data.
comm <- read.csv("20-22_species_composition_data_no_unk.csv", header = T)

# Remove the locations surveyed in 2021 and 2022 that were not surveyed in 2020 - aka, cm=0, cm=21, cm = 22, cm = 29.
comm<-comm[which(comm$cm_location!=21 & comm$cm_location!=0 & comm$cm_location!=22 & comm$cm_location!=29),]

# Make a group name for each row
comm$grp<-apply(comm[c(1,3,5,6,7)], 1, paste, collapse=":") # timepoint, block, transect_name, initial state

# Need to make each row a community using matrify.
commsub<-comm[,c(15,10,13)] # group, species_code, and count of each species for each transect. transects are rows.
commsub <-as.data.frame(commsub)
commtry<-matrify(commsub) # make it an expanded species matrix 
commtry$x[which(is.na(commtry$x))] <- 1 # "x" means that there were no individuals in the transect, but we are going to keep track of this as if it were a species
ncol(commtry) # how many species are we working with in our community matrix

# Store grouping row names as a column, then remove rownames.
commtry$grps<-rownames(commtry)
rownames(commtry)<-NULL
names(commtry)

# Split group info into columns for each variable
mat<-separate(commtry, 88, c("time","block","transect","init","treatment"), ":")
names(mat) #check
```

Composition dissimilarity * 2020 *

Main takeaways:

* Constrained proportion: variance of community composition explained by initial treatment + block is 77.38%. 
* Unexplained variance in community composition is 22.62%.
* The overall model of initial treatment+block significantly explains variation in the data. 
```{r, message=TRUE, warning=TRUE, include=TRUE, paged.print=FALSE, results='markup'}
# subset data where all t0 communities, insitu log and insitu open communities at t1 and t2 are included.
mat2 <- mat[which(mat$time=="t0"),]
mat2$grp<-apply(mat2[c(89,91)], 1, paste, collapse=":") # block, init as grouping
names(mat2) #check

# another df where the grouping variables are time, block and initial state
# each row is a transect in a certain year.
df<-mat2[,c(1:87, 93)]
df2 = df %>% mutate(across(.cols=1:87,.fns=as.numeric)) # make everything numeric
rownames(df2)<-NULL # remove rownames

## new with group vars
nublock<-separate(df2, 88, c("block", "init"), ":") # just looking at time, block & initial treatment

# want to sum across transects in same block X init treatment
nublock$sumgrp<-apply(mat2[c(89, 91)], 1, paste, collapse=":")
head(nublock)

# sum observations across initial X  block (group variable)
# this gives number of plants in each transect TYPE for each year in each block. should be 2 types X 3 years X 7 blocks rows 
blocksum<-rowsum(nublock[,c(1:87)], group=nublock$sumgrp)
blocksum$grps<-rownames(blocksum)
rownames(blocksum)<-NULL # remove rownames
nrow(blocksum) # it is 14 rows as expected 

## expand again
blocksum<-separate(blocksum, 88, c("block", "init"), ":")

# at the moment this includes where there were no plants ("x" column in matrix)
assemblies_t0<-blocksum[,c(1:87)]

# group - these are the treatment variables that need to be separately fed into the MDS analaysis from the community analysis.
group_init<-blocksum$init
group_block<-blocksum$block

# MDS 
ass.rel.t0<-decostand(assemblies_t0, method='hel') #standardize assemblies 
ass.rel.t0_NMS <- metaMDS(ass.rel.t0, distance = 'bray', k = 5) # run MDS 
stressplot(ass.rel.t0_NMS) # check fit

# scores
mds_scores_t0<-as.data.frame(vegan::scores(ass.rel.t0_NMS)$sites) # extract scores
mds_scores_t0$site<-rownames(vegan::scores(ass.rel.t0_NMS)$sites) # extract names 
mds_scores_t0$treatment<-group_init # grouping factor 1 
mds_scores_t0$block<-group_block # grouping factor 2 

# explaining factors
init<-as.factor(group_init) # grouping factor 1- convert to factor
block<-as.factor(group_block) # grouping factor 2- convert to factor

#### Redundancy analysis
# can look at significance of model where initial treatment and block explain variation in community
trt_tot_2<-rda(ass.rel.t0~init+block) # run model using standardized data 
summary(trt_tot_2)
anova.cca(trt_tot_2, step=1000, by="term") ## test for model significance

# Using varpart to look at contributions of initial treatment and block
var.mod2<-varpart(ass.rel.t0, init, block) # run model on standardized data
plot(var.mod2, bg=c("hotpink","skyblue"))
mtext("X1= Treatment; X2=Block", side=3)

# can test for significance of contribution of the fraction of initial treatment
# do this with partial redundancy analysis
trt_Frac<-rda(ass.rel.t0, init, block) # partial rda model
summary(trt_Frac) 
RsquareAdj(trt_Frac)$adj.r.squared #explanatory power
anova.cca(trt_Frac) ## this tells us if first condition, init, significantly contributes to overall variance explanation. 

# Extracting species scores and plotting 
# Species scores
species.scores<-as.data.frame(vegan::scores(ass.rel.t0_NMS,"species")) ## some species don't have scores
species.scores$species<-rownames(species.scores) 

### NMDS 1 and 2 
log<-mds_scores_t0[mds_scores_t0$treatment == "log", ][chull(mds_scores_t0[mds_scores_t0$treatment == 
                                                          "log", c("NMDS1", "NMDS2")]), ]

open<-mds_scores_t0[mds_scores_t0$treatment == "open", ][chull(mds_scores_t0[mds_scores_t0$treatment == 
                                                               "open", c("NMDS1", "NMDS2")]), ]

hulldat<-rbind(log,open)
 
nmds.plot<- ggplot()+
  theme_bw()+
  theme(panel.background = element_blank(),
        panel.grid.major = element_blank(),  #remove major-grid labels
        panel.grid.minor = element_blank(),  #remove minor-grid labels
        plot.background = element_blank(), 
        axis.text = element_text(size = 15),
        axis.title=element_text(size=20),
        legend.title=element_text(size=20), 
        legend.text=element_text(size=15))+
  geom_text_repel(data=species.scores, aes(NMDS1, NMDS2, label=species), alpha=0.9, size=5, col='darkgray')+
  geom_polygon(data=hulldat, aes(NMDS1, NMDS2, fill=treatment, group=treatment), alpha=0.3)+scale_fill_manual(values=c("#63A088","#56638A"), name="Treatment")+
  geom_point(data=mds_scores_t0, aes(NMDS1, NMDS2, shape=block, col=treatment), size=6)+ scale_shape_manual(values = c(14,15,16,17,11,18,8), name='Block')+
  scale_colour_manual(values=c("#63A088","#56638A"), name="Treatment")

print(nmds.plot)
```

Composition dissimilarity * 2021 *

Main takeaways:

* Constrained proportion: variance of community composition explained by initial treatment + block is 65.82%. 
* Unexplained variance in community composition is 34.18%.
* The overall model of initial treatment+block significantly explains variation in the data. 
```{r, message=FALSE, warning=FALSE, include=TRUE, paged.print=FALSE, results=TRUE}
# subset data where all t0 communities, insitu log and insitu open communities at t1 and t2 are included.
mat2 <- mat[which(mat$time=="t1" &  mat$treatment=="open" | mat$time=="t1" & mat$treatment=="insitu_log"),]
mat2$grp<-apply(mat2[c(89,91)], 1, paste, collapse=":") # block, init as grouping
names(mat2) #check

# another df where the grouping variables are time, block and initial state
# each row is a transect in a certain year.
df<-mat2[,c(1:87, 93)]
df2 = df %>% mutate(across(.cols=1:87,.fns=as.numeric)) # make everything numeric
rownames(df2)<-NULL # remove rownames

## new with group vars
nublock<-separate(df2, 88, c("block", "init"), ":") # just looking at time, block & initial treatment

# want to sum across transects in same block X init treatment
nublock$sumgrp<-apply(mat2[c(89, 91)], 1, paste, collapse=":")
head(nublock)

# sum observations across initial X  block (group variable)
# this gives number of plants in each transect TYPE for each year in each block. should be 2 types X 3 years X 7 blocks rows 
blocksum<-rowsum(nublock[,c(1:87)], group=nublock$sumgrp)
blocksum$grps<-rownames(blocksum)
rownames(blocksum)<-NULL # remove rownames
nrow(blocksum) # it is 14 rows as expected 

##  expand again
blocksum<-separate(blocksum, 88, c("block", "init"), ":")

# at the moment this includes where there were no plants ("x" column in matrix)
assemblies_t1<-blocksum[,c(1:87)]

# group - these are the treatment variables that need to be separately fed into the MDS analaysis from the community analysis.
group_init<-blocksum$init
group_block<-blocksum$block

# MDS 
ass.rel.t1<-decostand(assemblies_t1, method='hel') #standardize assemblies 
ass.rel.t1_NMS <- metaMDS(ass.rel.t1, distance = 'bray', k = 5) # run MDS 
stressplot(ass.rel.t1_NMS) # check fit

# scores
mds_scores_t1<-as.data.frame(vegan::scores(ass.rel.t1_NMS)$sites) # extract scores
mds_scores_t1$site<-rownames(vegan::scores(ass.rel.t1_NMS)$sites) # extract names 
mds_scores_t1$treatment<-group_init # grouping factor 1 
mds_scores_t1$block<-group_block # grouping factor 2 

# explaining factors
init<-as.factor(group_init) # grouping factor 1- convert to factor
block<-as.factor(group_block) # grouping factor 2- convert to factor

#### rda model analysis & results #### 
# can look at significance of model where initial treatment and block explain variation in community
trt_tot_2<-rda(ass.rel.t1~init+block) # run model using standardized data 
summary(trt_tot_2)
anova.cca(trt_tot_2, step=1000, by="term") ## test for model significance

# can model using varpart to look at contributions of initial treatment and block
var.mod2<-varpart(ass.rel.t1, init, block) # run model on standardized data
plot(var.mod2, bg=c("hotpink","skyblue"))
mtext("X1= Treatment; X2=Block", side=3)

## can test for significance of contribution of the fraction of initial treatment
# do this with partial redundancy analysis
trt_Frac<-rda(ass.rel.t1, init, block) # partial rda model
summary(trt_Frac) 
RsquareAdj(trt_Frac)$adj.r.squared #explanatory power
anova.cca(trt_Frac) ## this tells us if first condition, init, significantly contributes to overall variance explanation. 

### extracting species scores and plotting 
# species scores
species.scores<-as.data.frame(vegan::scores(ass.rel.t1_NMS,"species")) ## some species don't have scores
species.scores$species<-rownames(species.scores) 

### NMDS 1 and 2 
log<-mds_scores_t1[mds_scores_t1$treatment == "log", ][chull(mds_scores_t1[mds_scores_t1$treatment == 
                                                          "log", c("NMDS1", "NMDS2")]), ]

open<-mds_scores_t1[mds_scores_t1$treatment == "open", ][chull(mds_scores_t1[mds_scores_t1$treatment == 
                                                               "open", c("NMDS1", "NMDS2")]), ]

hulldat<-rbind(log,open)
 
nmds.plot <- ggplot()+
  theme_bw()+
  theme(panel.background = element_blank(),
        panel.grid.major = element_blank(),  #remove major-grid labels
        panel.grid.minor = element_blank(),  #remove minor-grid labels
        plot.background = element_blank(), 
        axis.text = element_text(size = 15),
        axis.title=element_text(size=20),
        legend.title=element_text(size=20), 
        legend.text=element_text(size=15))+
  geom_text_repel(data=species.scores, aes(NMDS1, NMDS2, label=species), alpha=0.9, size=5, col='darkgray')+
  geom_polygon(data=hulldat, aes(NMDS1, NMDS2, fill=treatment, group=treatment), alpha=0.3)+scale_fill_manual(values=c("#63A088","#56638A"), name="Treatment")+
  geom_point(data=mds_scores_t1, aes(NMDS1, NMDS2, shape=block, col=treatment), size=6)+ scale_shape_manual(values = c(14,15,16,17,11,18,8), name='Block')+
  scale_colour_manual(values=c("#63A088","#56638A"), name="Treatment")

print(nmds.plot)
```

Composition dissimilarity * 2022 *

Main takeaways:

* Constrained proportion: variance of community composition explained by initial treatment + block is 67.05%. 
* Unexplained variance in community composition is 32.95%.
* The overall model of initial treatment+block significantly explains variation in the data. 
```{r, message=FALSE, warning=FALSE, include=TRUE, paged.print=FALSE, results=TRUE}
# subset data where all t0 communities, insitu log and insitu open communities at t1 and t2 are included.
mat2 <- mat[which(mat$time=="t2" &  mat$treatment=="open" | mat$time=="t2" & mat$treatment=="insitu_log"),]
mat2$grp<-apply(mat2[c(89,91)], 1, paste, collapse=":") # block, init as grouping
names(mat2) #check

# another df where the grouping variables are time, block and initial state
# each row is a transect in a certain year.
df<-mat2[,c(1:87, 93)]
df2 = df %>% mutate(across(.cols=1:87,.fns=as.numeric)) # make everything numeric
rownames(df2)<-NULL # remove rownames

## new with group vars
nublock<-separate(df2, 88, c("block", "init"), ":") # just looking at time, block & initial treatment

# want to sum across transects in same block X init treatment
nublock$sumgrp<-apply(mat2[c(89, 91)], 1, paste, collapse=":")
head(nublock)

# sum observations across initial X  block (group variable)
# this gives number of plants in each transect TYPE for each year in each block. should be 2 types X 3 years X 7 blocks rows 
blocksum<-rowsum(nublock[,c(1:87)], group=nublock$sumgrp)
blocksum$grps<-rownames(blocksum)
rownames(blocksum)<-NULL # remove rownames
nrow(blocksum) # it is 14 rows as expected 

##  expand again
blocksum<-separate(blocksum, 88, c("block", "init"), ":")

# at the moment this includes where there were no plants ("x" column in matrix)
assemblies_t2<-blocksum[,c(1:87)]

# group - these are the treatment variables that need to be separately fed into the MDS analaysis from the community analysis.
group_init<-blocksum$init
group_block<-blocksum$block

# MDS 
ass.rel.t2<-decostand(assemblies_t2, method='hel') #standardize assemblies 
ass.rel.t2_NMS <- metaMDS(ass.rel.t2, distance = 'bray', k = 5) # run MDS 
stressplot(ass.rel.t2_NMS) # check fit

# scores
mds_scores_t2<-as.data.frame(vegan::scores(ass.rel.t2_NMS)$sites) # extract scores
mds_scores_t2$site<-rownames(vegan::scores(ass.rel.t2_NMS)$sites) # extract names 
mds_scores_t2$treatment<-group_init # grouping factor 1 
mds_scores_t2$block<-group_block # grouping factor 2 

# explaining factors
init<-as.factor(group_init) # grouping factor 1- convert to factor
block<-as.factor(group_block) # grouping factor 2- convert to factor

#### rda model analysis & results #### 
# can look at significance of model where initial treatment and block explain variation in community
trt_tot_2<-rda(ass.rel.t2~init+block) # run model using standardized data 
summary(trt_tot_2)
anova.cca(trt_tot_2, step=1000, by="term") ## test for model significance

# can model using varpart to look at contributions of initial treatment and block
var.mod2<-varpart(ass.rel.t2, init, block) # run model on standardized data
plot(var.mod2, bg=c("hotpink","skyblue"))
mtext("X1= Treatment; X2=Block", side=3)

## can test for significance of contribution of the fraction of initial treatment
# do this with partial redundancy analysis
trt_Frac<-rda(ass.rel.t2, init, block) # partial rda model
summary(trt_Frac) 
RsquareAdj(trt_Frac)$adj.r.squared #explanatory power
anova.cca(trt_Frac) ## this tells us if first condition, init, significantly contributes to overall variance explanation. 

### extracting species scores and plotting 
# species scores
species.scores.t2<-as.data.frame(vegan::scores(ass.rel.t2_NMS,"species")) ## some species don't have scores
species.scores.t2$species<-rownames(species.scores.t2) 

### NMDS 1 and 2 
log<-mds_scores_t2[mds_scores_t2$treatment == "log", ][chull(mds_scores_t2[mds_scores_t2$treatment == 
                                                          "log", c("NMDS1", "NMDS2")]), ]

open<-mds_scores_t2[mds_scores_t2$treatment == "open", ][chull(mds_scores_t2[mds_scores_t2$treatment == 
                                                               "open", c("NMDS1", "NMDS2")]), ]

hulldat<-rbind(log,open)
 
nmds.plot <- ggplot()+
  theme_bw()+
  theme(panel.background = element_blank(),
        panel.grid.major = element_blank(),  #remove major-grid labels
        panel.grid.minor = element_blank(),  #remove minor-grid labels
        plot.background = element_blank(), 
        axis.text = element_text(size = 15),
        axis.title=element_text(size=20),
        legend.title=element_text(size=20), 
        legend.text=element_text(size=15))+
  geom_text_repel(data=species.scores.t2, aes(NMDS1, NMDS2, label=species), alpha=0.9, size=5, col='darkgray')+
  geom_polygon(data=hulldat, aes(NMDS1, NMDS2, fill=treatment, group=treatment), alpha=0.3)+scale_fill_manual(values=c("#63A088","#56638A"), name="Treatment")+
  geom_point(data=mds_scores_t2, aes(NMDS1, NMDS2, shape=block, col=treatment), size=6)+ scale_shape_manual(values = c(14,15,16,17,11,18,8), name='Block')+
  scale_colour_manual(values=c("#63A088","#56638A"), name="Treatment")
  
print(nmds.plot)
```
Composition dissimilarity * 2020 - 2022 *
### 3. rda: composition dissimilarity all years with controlling effect of time and block
Main takeaways:

* Constrained proportion: variance of community composition explained by initial treatment + block + time is 50.31%. 
* Unexplained variance in community composition is 49.59%.
* The overall model of initial treatment+block+time significantly explains variation in the data. 
Main takeaways:

* time and block explains 44.33% of variations in plant compositions
* initial treatment explains 6.08% of variations in plant compositions
* 49.59% of variations are not explained
```{r}
# subset data where all t0 communities, insitu log and insitu open communities at t1 and t2 are included.
mat3 <- mat[which(mat$time=="t0" |  mat$treatment=="open" | mat$treatment=="insitu_log"),]
mat3$grp<-apply(mat3[c(88,89,91)], 1, paste, collapse=":") # block, init as grouping
names(mat3) #check

# another df where the grouping variables are time, block and initial state
# each row is a transect in a certain year.
df<-mat3[,c(1:87, 93)]
df2 = df %>% mutate(across(.cols=1:87,.fns=as.numeric)) # make everything numeric
rownames(df2)<-NULL # remove rownames

## new with group vars
nublock<-separate(df2, 88, c("time", "block", "init"), ":") # just looking at time, block & initial treatment

# want to sum across transects in same block X init treatment
nublock$sumgrp<-apply(mat3[c(88,89, 91)], 1, paste, collapse=":")
head(nublock)

# sum observations across initial X  block (group variable)
# this gives number of plants in each transect TYPE for each year in each block. should be 2 types X 3 years X 7 blocks rows 
blocksum<-rowsum(nublock[,c(1:87)], group=nublock$sumgrp)
blocksum$grps<-rownames(blocksum)
rownames(blocksum)<-NULL # remove rownames
nrow(blocksum) # it is 42 rows as expected 

##  expand again
blocksum<-separate(blocksum, 88, c("time", "block", "init"), ":")

# at the moment this includes where there were no plants ("x" column in matrix)
assemblies_t012<-blocksum[,c(1:87)]

# group - these are the treatment variables that need to be separately fed into the MDS analaysis from the community analysis.
group_init<-blocksum$init
group_block<-blocksum$block
group_time<-blocksum$time

# MDS 
ass.rel.t012<-decostand(assemblies_t012, method='hel') #standardize assemblies 
ass.rel.t012_NMS <- metaMDS(ass.rel.t012, distance = 'bray', k = 5) # run MDS 
stressplot(ass.rel.t012_NMS) # check fit

# scores
mds_scores_t012<-as.data.frame(vegan::scores(ass.rel.t012_NMS)$sites) # extract scores
mds_scores_t012$site<-rownames(vegan::scores(ass.rel.t012_NMS)$sites) # extract names 
mds_scores_t012$treatment<-group_init # grouping factor 1 
mds_scores_t012$block<-group_block # grouping factor 2 
mds_scores_t012$time<-group_time # grouping factor 3

# explaining factors
init<-as.factor(group_init) # grouping factor 1- convert to factor
block<-as.factor(group_block) # grouping factor 2- convert to factor
time<-as.factor(group_time)

#### rda model analysis & results #### 
# can look at significance of model where initial treatment and block explain variation in community
trt_tot_2<-rda(ass.rel.t012~init+block+time) # run model using standardized data 
summary(trt_tot_2)
anova.cca(trt_tot_2, step=1000, by="term") ## test for model significance

# can model using varpart to look at contributions of initial treatment and block
var.mod2<-varpart(ass.rel.t012, init, block, time) # run model on standardized data
plot(var.mod2, bg=c("hotpink","skyblue","lightyellow"))
mtext("X1= Treatment; X2=Block; X3=time", side=3)

## can test for significance of contribution of the fraction of initial treatment
# do this with partial redundancy analysis
trt_Frac<-rda(ass.rel.t012~ init +Condition(block + time)) # partial rda model
summary(trt_Frac) 
RsquareAdj(trt_Frac)$adj.r.squared #explanatory power
anova.cca(trt_Frac) ## this tells us if first condition, init, significantly contributes to overall variance explanation. 

### extracting species scores and plotting 
# species scores
species.scores<-as.data.frame(vegan::scores(ass.rel.t012_NMS,"species")) ## some species don't have scores
species.scores$species<-rownames(species.scores) 

### NMDS 1 and 2 
log<-mds_scores_t012[mds_scores_t012$treatment == "log", ][chull(mds_scores_t012[mds_scores_t012$treatment == 
                                                          "log", c("NMDS1", "NMDS2")]), ]

open<-mds_scores_t012[mds_scores_t012$treatment == "open", ][chull(mds_scores_t012[mds_scores_t012$treatment == 
                                                               "open", c("NMDS1", "NMDS2")]), ]

hulldat<-rbind(log,open)

options(ggrepel.max.overlaps = Inf)
nmds.plot <- ggplot()+
  theme_bw()+
  theme(panel.background = element_blank(),
        panel.grid.major = element_blank(),  #remove major-grid labels
        panel.grid.minor = element_blank(),  #remove minor-grid labels
        plot.background = element_blank(), 
        axis.text = element_text(size = 15),
        axis.title=element_text(size=20),
        legend.title=element_text(size=20), 
        legend.text=element_text(size=15))+
  geom_text_repel(data=species.scores, aes(NMDS1, NMDS2, label=species), alpha=0.9, size=5, col='darkgray')+
  geom_polygon(data=hulldat, aes(NMDS1, NMDS2, fill=treatment, group=treatment), alpha=0.3)+scale_fill_manual(values=c("#63A088","#56638A"), name="Treatment")+
  geom_point(data=mds_scores_t012, aes(NMDS1, NMDS2, shape=block, col=treatment), size=6)+ scale_shape_manual(values = c(14,15,16,17,11,18,8), name='Block')+
  scale_colour_manual(values=c("#63A088","#56638A"), name="Treatment")
 
print(nmds.plot) 
```

#### *Interpretation* 

### **Q2 Why are plant communities in fallen log patches different from patches in the open?**<br>
#### *Overview of results* <br> 

#### *Statistical Methods* <br>

#### *Analysis*<br>
- nutrient analysis (nutrient composition ~ log vs open; abundance ~ nutrient composition , diversity ~ nutrient composition, composition ~ nutrient composition)

Set global options
```{r include=FALSE}
knitr::opts_chunk$set(message = FALSE)
library(ggplot2)
library(ggpubr)
library(dplyr)
library(xlsx)
library(lme4)
library(emmeans)
library(pscl)
library(glmmTMB)
library(tidyr)
library(DHARMa)
library(ggplot2)
library(AICcmodavg)
library(ggpubr)

# Set up nutrient analysis data
nutrient <- read.csv("Nutrient.csv", header = T)
nutrient <-separate(nutrient,2 , c("block","plot"), "_")
nutrient <- nutrient[,2:17]

# Visualise data
Nu <- c("ammonium.nitrogen", "nitrate.nitrogen", "phosphorus", "potassium", "organic.carbon", "conductivity", "pH.CaCl2", "pH.H2O", "prewash.exch.ca", "prewash.exch.k", "prewash.exch.mg", "prewash.exch.na")

for (element in Nu) {
    print(
      ggplot(nutrient, aes(x = init, y= !!rlang::sym(element))) +
      geom_boxplot() + 
      theme_bw() +
      labs(x="Plot treatment", y= element)
    )
}
```

Nutrient composition comparison between log and open
```{r, include=TRUE, results='hold', fig.width = 8, fig.height = 8}
Nu <- c("ammonium.nitrogen", "nitrate.nitrogen", "phosphorus", "potassium", "organic.carbon", "conductivity", "pH.CaCl2", "pH.H2O", "prewash.exch.ca", "prewash.exch.k", "prewash.exch.mg", "prewash.exch.na")

wilcox_results <- data.frame(Element = character(),
                                W = numeric(),
                                p_value = numeric(),
                                stringsAsFactors = FALSE)

# Perform Wilcoxon rank sum test for each element between treatments
nutrient$init <- as.factor(nutrient$init)
for (element in Nu) {
    result <- wilcox.test(get(element) ~ init, data = nutrient, exact=TRUE)
    wilcox_results <- rbind(wilcox_results, 
                               data.frame(Element = element,
                                          W = result$statistic,
                                          p_value = result$p.value,
                                          stringsAsFactors = FALSE,
                                          row.names = NULL))
} # only organic carbon is significantly different between the two plot types


plots_list <- list()

for (element in c(Nu, "organic.carbon")) {
  if (element == "organic.carbon") {
    plot <- ggplot(nutrient, aes(x = init, y = organic.carbon)) +
      geom_boxplot() + 
      theme_bw() +
      labs(x = NULL, y = "organic.carbon") + 
      scale_x_discrete(labels=c('log', 'open')) +
      geom_signif(comparisons = list(c("log", "open")),
                  map_signif_level = TRUE,
                  textsize = 5, vjust = 0.5, y_position = 1.6, tip_length = 0) + 
      scale_y_continuous(expand = c(0,0.1))+
      theme(
    plot.background = element_blank(),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_blank()) + 
      theme(axis.line = element_line(color = 'black')) 
    
  } else {
    plot <- ggplot(nutrient, aes(x = init, y = !!rlang::sym(element))) +
      geom_boxplot() + 
      theme_bw() +
      labs(x = NULL, y = element) + 
      scale_x_discrete(labels=c('log', 'open')) +
      theme(
    plot.background = element_blank(),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_blank()) + theme(axis.line = element_line(color = 'black')) 
  }
  
  plots_list[[element]] <- plot
}

all.bp <- ggarrange(plotlist=plots_list, ncol=3, nrow=4, common.legend =TRUE, legend="bottom",align = "v")

all.bp <- annotate_figure(all.bp, bottom = "Plot treatment")
# Show the final plot
print(all.bp)
```

Abundance ~ nutrient composition 
- None of the nutrient elements explains count of plants at the transect level
```{r, message=FALSE, warning=FALSE, include=TRUE, paged.print=FALSE, results=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# packages

require(vegan)
require(dplyr)
require(tidyr)
require(labdsv)
require(stringr)
require(ggplot2)
require(ggrepel)
require(lme4)
require(emmeans)
require(ggpubr)

##### data wrangling #####

# This dataset includes unknown species.
comm <- read.csv("20-22_species_composition_data_w_unk.csv", header=T)

# Remove the locations surveyed in 2021 and 2022 that were not surveyed in 2020 - aka, cm=0, cm=21, cm = 22, cm = 29.
comm<-comm[which(comm$cm_location!=21 & comm$cm_location!=0 & comm$cm_location!=22 & comm$cm_location!=29),]

# make a group name for each row
comm$grp<-apply(comm[c(1,3,5,6,7)], 1, paste, collapse=":") # timepoint, block, transect_name, initial state

# Need to make each row a community using matrify.
commsub<-comm[,c(15,10,13)] # group, species_code, and count of each species for each transect. transects are rows.
commsub <-as.data.frame(commsub)
commtry<-matrify(commsub) # make it an expanded species matrix 
commtry$x[which(is.na(commtry$x))] <- 1 # "x" means that there were no individuals in the transect, but we are going to keep track of this as if it were a species
ncol(commtry) # how many species are we working with in our community matrix

# Store grouping row names as a column, then remove rownames.
commtry$grps<-rownames(commtry)
rownames(commtry)<-NULL
names(commtry)

# Split group info into columns for each variable.
mat<-separate(commtry, 107, c("time","block","transect","init", "treatment"), ":")
names(mat) #check

# Add groupname using time, block, init columns.
mat$grp1<-apply(mat[c(107:110)], 1, paste, collapse=":")
mat$grp2<-apply(mat[c(107:111)], 1, paste, collapse=":")
names(mat) #check

# Another df where the grouping variables are time, block, transect and initial state.
# Each row is a transect in a certain year.
df<-mat[,c(1:106,113)]
# df2 = with treatment in the grouping
df2 = df %>% mutate(across(.cols=1:106,.fns=as.numeric))
rownames(df2)<-NULL # remove rownames

##### Abundance analysis for 2020 (t0) AND in-situ log and in-situ open plots in 2021 (t1) and 2022 (t2)

# Sum observations across initial X transect X time X  block X treatment (group variable).
# This gives number of plants in each row observation (transect level).
blocksum2<-rowsum(df2[,c(1:106)], group=df2$grp2)
blocksum2$grps<-rownames(blocksum2)
rownames(blocksum2)<-NULL # remove rownames

# Add in group vars.
nublock2<-separate(blocksum2, 107, c("time","block","transect","init", "treatment"), ":")
nublock2$total<-rowSums(nublock2[,c(1:106)])
nublock2$presence<-ifelse(nublock2$total > 0,  1, 0)

# Subset data where before treatments installed (t0), in-situ log and in-situ open from t1 and t2 are included.
# Hence only absolute log effect and absolute open effect are concerned
dat_t0_insitu<-nublock2[which(nublock2$time=="t0" |  nublock2$treatment=="open" |  nublock2$treatment=="insitu_log"),]

# look at plant abundance in log vs open 
# look at range of data - what family should i use? 
range(dat_t0_insitu$total)
nutrient_join <- nutrient[,c(1,3, 5:16)]
dat_t0_insitu <- inner_join(dat_t0_insitu, nutrient_join, by = c("init", "block"))

# since samples from t1 and t2 from are mainly from the same plots as t0. These are not independent replicates and tend to correlated with each other.
# including year and block as random effects
# (1|year) + (1|block) as we think the effect of init on total is the same (slope) but the intercept differ amongst block and year
# but since we have a greater number of sample from t0, data from t0 will contribute more to the variance in abundance.
# see https://bookdown.org/steve_midway/DAR/random-effects.html#pld-example

# 2020 - 2022 #
Nu <- c("ammonium.nitrogen", "nitrate.nitrogen", "phosphorus", "potassium", "organic.carbon", "conductivity", "pH.CaCl2", "pH.H2O", "prewash.exch.ca", "prewash.exch.k", "prewash.exch.mg", "prewash.exch.na")

result_df <- data.frame(Element = character(), P_Value = numeric(), stringsAsFactors = FALSE)

for (element in Nu) {
  formula <- as.formula(paste("total ~", element, "+ (1|block) + (1|time)", sep = ""))
  
  abun.mod <- glmer(formula, data = dat_t0_insitu, family = poisson)
  model_summary <- summary(abun.mod)

  p_value <- coef(summary(abun.mod))[, "Pr(>|z|)"][2]  
  
  result_df <- rbind(result_df, data.frame(Element = element, P_Value = p_value, stringsAsFactors = FALSE))
}

print(result_df)


# only 2022
result_2022 <- data.frame(Element = character(), P_Value = numeric(), stringsAsFactors = FALSE)

for (element in Nu) {
  formula <- as.formula(paste("total ~", element, "+ (1|block)", sep = ""))
  abun.mod <- glmer(formula, data = dat_t0_insitu, family = poisson, subset = (time == "t2"))
  model_summary <- summary(abun.mod)

  p_value <- coef(summary(abun.mod))[, "Pr(>|z|)"][2]  
  
  result_2022 <- rbind(result_df, data.frame(Element = element, P_Value = p_value, stringsAsFactors = FALSE))
}

# Print or use the result dataframe
print(result_2022)
```

Diversity ~ nutrient composition
```{r, message=FALSE, warning=FALSE, include=TRUE, paged.print=FALSE, results='markup', fig.width =8, fig.height=8}
require(vegan)
require(dplyr)
require(tidyr)
require(labdsv)
require(stringr)
require(ggplot2)
require(ggrepel)
require(lme4)
require(emmeans)
require(lmerTest)
require(performance)
require(ggpubr)
require(DHARMa)

# This dataset does not include unknown data.
comm <- read.csv("20-22_species_composition_data_no_unk.csv", header = T)

# Remove the locations surveyed in 2021 and 2022 that were not surveyed in 2020 - aka, cm=0, cm=21, cm = 22, cm = 29.
comm<-comm[which(comm$cm_location!=21 & comm$cm_location!=0 & comm$cm_location!=22 & comm$cm_location!=29),]

# make a group name for each row
comm$grp<-apply(comm[c(1,3,5,6,7)], 1, paste, collapse=":") # timepoint, block, transect_name, initial state

# Need to make each row a community using matrify
commsub<-comm[,c(15,10,13)] 

# group, species_code, and count of each species for each transect. transects are rows.
commsub <-as.data.frame(commsub)
commtry<-labdsv::matrify(commsub) # make it an expanded species matrix 
commtry$x[which(is.na(commtry$x))] <- 1  # "x" means that there were no individuals in the transect, but we are going to keep track of this as if it were a species
ncol(commtry) # how many species are we working with in our community matrix

# Store grouping row names as a column, then remove rownames.
commtry$grps<-rownames(commtry)
rownames(commtry)<-NULL
names(commtry)

# Split group info into columns for each variable
mat<-separate(commtry, 88, c("time","block","transect","init","treatment"), ":")
names(mat) #check

# Add groupname using time, block, init columns
mat$grp<-apply(mat[c(88:92)], 1, paste, collapse=":")
names(mat) #check

# Another df where the grouping variables are time, block, transect and initial state.
# Each row is a transect in a certain year.
df<-mat[,c(1:87,93)]
df2 = df %>% mutate(across(.cols=1:87,.fns=as.numeric)) # make everything numeric
rownames(df2)<-NULL # remove rownames

###### Species diversity analysis for 2020 - 2022 data (Shannon diversity on transect level) 
numat = mat %>% mutate(across(.cols=1:87,.fns=as.numeric)) # make everything numeric

# sum species for each group (grouped by init, transect, block, time)
nudat<-numat%>% 
  group_by(time, block, transect, init, treatment) %>% summarise(across(where(is.numeric), sum))

# make a data frame
dat<-as.data.frame(nudat) # this df contains transect levels from all years
dat<-dat[which(dat$time=="t0" |  dat$treatment=="open" |  dat$treatment=="insitu_log"),]

#estimate diversity for each row/group. don't include 'x' 

# no groups, just estimate diversity of each row
est<-dat[,c(6:91)]
dat$diversity<-diversity(est, index='shannon') 
nutrient_join <- nutrient[,c(1,3, 5:16)]
dat <- inner_join(dat, nutrient_join, by = c("init", "block"))

###### We used a hurdle model since the data is zero-inflated
# separate into zero and non-zero observations
dat$non_zero <- ifelse(dat$diversity > 0, 1, 0)

# Non-zero data is an approximal Gaussian distribution
hist(dat$diversity[dat$non_zero ==1], xlab = "Shannon diversity index (non-zero)", main = "Histogram of Shannon diversity index (non-zero, all years, transect level)") # visually it resembles a lot like a Gaussian distribution 

# Gaussian distribution produced the best-fitting ggplot
dat_nonzerodat <- dat[dat$non_zero == 1, ]
ggplot(dat_nonzerodat, aes(sample = diversity)) + 
                  geom_qq(distribution = qnorm) + 
                  geom_qq_line(distribution = qnorm) +
                  ggtitle("normal")

# Hurdle model part 1. Logistic regression to predict the probability of non-zero.
# Ppen and log environment does determine the probability of non-zero diversity index
# 0 Shannon diversity index =/= zero plants

# 2020-2022 #
Nu <- c("ammonium.nitrogen", "nitrate.nitrogen", "phosphorus", "potassium", "organic.carbon", "conductivity", "pH.CaCl2", "pH.H2O", "prewash.exch.ca", "prewash.exch.k", "prewash.exch.mg", "prewash.exch.na")

hurd.mod.1.t012 <- data.frame(Element = character(), P_Value = numeric(), stringsAsFactors = FALSE)

for (element in Nu) {
  formula <- as.formula(paste("non_zero ~", element, "+ (1|block) + (1|time)", sep = ""))
  abun.mod <- glmer(formula, data = dat, family = binomial)
  model_summary <- summary(abun.mod)

  p_value <- coef(summary(abun.mod))[, "Pr(>|z|)"][2]  
  
  hurd.mod.1.t012 <- rbind(hurd.mod.1.t012, data.frame(Element = element, P_Value = p_value, stringsAsFactors = FALSE))
}

# Print or use the result dataframe
print(hurd.mod.1.t012)


hurd.mod.2.t012 <- data.frame(Element = character(), P_Value = numeric(), stringsAsFactors = FALSE)

for (element in Nu) {
  formula <- as.formula(paste("diversity ~", element, "+ (1|block) + (1|time)", sep = ""))
  abun.mod <- lmer(formula, data = dat, subset = (non_zero == 1))
  model_summary <- summary(abun.mod)

  p_value <- coef(summary(abun.mod))[, "Pr(>|t|)"][2]  
  
  hurd.mod.2.t012 <- rbind(hurd.mod.2.t012, data.frame(Element = element, P_Value = p_value, stringsAsFactors = FALSE))
}

# Print or use the result dataframe
print(hurd.mod.2.t012)
 
ggplot(dat[dat$non_zero==1,], aes(x = organic.carbon, y = diversity)) +
  geom_point() +
  geom_smooth(method = "glm")+
  theme_bw() +
  labs(x = "Organic carbon (mg/kg)", y = "Shannon diversity index")

# 2022 #
# model occurrence of zeros
hurd.mod.1.t2 <- data.frame(Element = character(), P_Value = numeric(), Significance = character(), stringsAsFactors = FALSE)

for (element in Nu) {
  formula <- as.formula(paste("non_zero ~", element, "+ (1|block)", sep = ""))
  abun.mod <- glmer(formula, data = dat, subset = (time == "t2"), family = binomial)
  model_summary <- summary(abun.mod)

  p_value <- coef(summary(abun.mod))[, "Pr(>|z|)"][2]  
 
   significance <- ifelse(p_value < 0.05, "*", "NS")
  
  hurd.mod.1.t2 <- rbind(hurd.mod.1.t2, data.frame(Element = element, P_Value = p_value,Significance = significance, stringsAsFactors = FALSE))
}

# Print or use the result dataframe
print(hurd.mod.1.t2)


# model diversity
hurd.mod.2.t2 <- data.frame(Element = character(), P_Value = numeric(), Significance = character(), stringsAsFactors = FALSE)

for (element in Nu) {
  formula <- as.formula(paste("diversity ~", element, "+ (1|block)", sep = ""))
  abun.mod <- lmer(formula, data = dat, subset = (time == "t2" & non_zero == 1))
  model_summary <- summary(abun.mod)

  p_value <- coef(summary(abun.mod))[, "Pr(>|t|)"][2]  

  significance <- ifelse(p_value < 0.05, "*", "NS")

  hurd.mod.2.t2 <- rbind(hurd.mod.2.t2, data.frame(Element = element, P_Value = p_value, Significance = significance, stringsAsFactors = FALSE))
  }

# Print or use the result dataframe
print(hurd.mod.2.t2)
```
Composition ~ nutrient composition
```{r, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE, results='markup', fig.width =8, fig.height=8}
# packages
library(tidyverse)
require(vegan)
require(dplyr)
require(tidyr)
require(labdsv)
require(stringr)
require(ggplot2)
require(ggrepel)
require(lme4)
require(emmeans)
require(lmerTest)
require(performance)
require(ggpubr)

# Data wrangling
# This data set does not include unknown data.
comm <- read.csv("20-22_species_composition_data_no_unk.csv", header = T)

# Remove the locations surveyed in 2021 and 2022 that were not surveyed in 2020 - aka, cm=0, cm=21, cm = 22, cm = 29.
comm<-comm[which(comm$cm_location!=21 & comm$cm_location!=0 & comm$cm_location!=22 & comm$cm_location!=29),]

# Make a group name for each row
comm$grp<-apply(comm[c(1,3,5,6,7)], 1, paste, collapse=":") # timepoint, block, transect_name, initial state

# Need to make each row a community using matrify.
commsub<-comm[,c(15,10,13)] # group, species_code, and count of each species for each transect. transects are rows.
commsub <-as.data.frame(commsub)
commtry<-matrify(commsub) # make it an expanded species matrix 
commtry$x[which(is.na(commtry$x))] <- 1 # "x" means that there were no individuals in the transect, but we are going to keep track of this as if it were a species
ncol(commtry) # how many species are we working with in our community matrix

# Store grouping row names as a column, then remove rownames.
commtry$grps<-rownames(commtry)
rownames(commtry)<-NULL
names(commtry)

# Split group info into columns for each variable
mat<-separate(commtry, 88, c("time","block","transect","init","treatment"), ":")
names(mat) #check
```

* 2022*
```{r, message=FALSE, warning=FALSE, include=TRUE, paged.print=FALSE, results=TRUE}
# subset data where all t0 communities, insitu log and insitu open communities at t1 and t2 are included.
mat2 <- mat[which(mat$time=="t2" &  mat$treatment=="open" | mat$time=="t2" & mat$treatment=="insitu_log"),]
mat2$grp<-apply(mat2[c(89,91)], 1, paste, collapse=":") # block, init as grouping
names(mat2) #check

# another df where the grouping variables are time, block and initial state
# each row is a transect in a certain year.
df<-mat2[,c(1:87, 93)]
df2 = df %>% mutate(across(.cols=1:87,.fns=as.numeric)) # make everything numeric
rownames(df2)<-NULL # remove rownames

## new with group vars
nublock<-separate(df2, 88, c("block", "init"), ":") # just looking at time, block & initial treatment

# want to sum across transects in same block X init treatment
nublock$sumgrp<-apply(mat2[c(89, 91)], 1, paste, collapse=":")
head(nublock)

# sum observations across initial X  block (group variable)
# this gives number of plants in each transect TYPE for each year in each block. should be 2 types X 3 years X 7 blocks rows 
blocksum<-rowsum(nublock[,c(1:87)], group=nublock$sumgrp)
blocksum$grps<-rownames(blocksum)
rownames(blocksum)<-NULL # remove rownames
nrow(blocksum) # it is 14 rows as expected 

##  expand again
blocksum<-separate(blocksum, 88, c("block", "init"), ":")
nutrient_join <- nutrient[,c(1,3,5:16)]
blocksum <- inner_join(blocksum, nutrient_join, by = c("init", "block"))
  
# at the moment this includes where there were no plants ("x" column in matrix)
assemblies_t2<-blocksum[,c(1:87)]

# group - these are the treatment variables that need to be separately fed into the MDS analaysis from the community analysis.
group_init<-blocksum$init
group_block<-blocksum$block
group_nutrient <-blocksum[, 90:101]

# MDS 
ass.rel.t2<-decostand(assemblies_t2, method='hel') #standardize assemblies 
ass.rel.t2_NMS <- metaMDS(ass.rel.t2, distance = 'bray', k = 5) # run MDS 
stressplot(ass.rel.t2_NMS) # check fit
en.nutrient = envfit(ass.rel.t2_NMS, group_nutrient, permutations = 999, na.rm = TRUE)
# plot(ass.rel.t2_NMS) 
# plot(en.nutrient)
print(en.nutrient) ########## it is basically saying most of the nutrient does not affect the composition of plants.

# we have created our NMS as ass.rel.t2_NMS
# scores
mds_scores_t2<-as.data.frame(vegan::scores(ass.rel.t2_NMS)$sites) # extract scores
mds_scores_t2$site<-rownames(vegan::scores(ass.rel.t2_NMS)$sites) # extract names 
mds_scores_t2$treatment<-group_init # grouping factor 1 
mds_scores_t2$block<-group_block # grouping factor 2 
mds_scores_t2 <- cbind(mds_scores_t2, group_nutrient)
en_coord_cont = as.data.frame(vegan::scores(en.nutrient, "vectors")) * ordiArrowMul(en.nutrient)

# explaining factors
init<-as.factor(group_init) # grouping factor 1- convert to factor
block<-as.factor(group_block) # grouping factor 2- convert to factor
nutri<-as.factor(group_nutrient)

#### rda model analysis & results #### 
# can look at significance of model where initial treatment and block explain variation in community
trt_tot_2<-rda(ass.rel.t2~init+block) # run model using standardized data 
summary(trt_tot_2)
anova.cca(trt_tot_2, step=1000, by="term") ## test for model significance

# can model using varpart to look at contributions of initial treatment and block
var.mod2<-varpart(ass.rel.t2, init, block) # run model on standardized data
plot(var.mod2, bg=c("hotpink","skyblue"))
mtext("X1= initial treatment; X2=Block", side=3)

## can test for significance of contribution of the fraction of initial treatment
# do this with partial redundancy analysis
trt_Frac<-rda(ass.rel.t2, init, block) # partial rda model
summary(trt_Frac) 
RsquareAdj(trt_Frac)$adj.r.squared #explanatory power
anova.cca(trt_Frac) ## this tells us if first condition, init, significantly contributes to overall variance explanation. 

### extracting species scores and plotting 
# species scores
species.scores.t2 <-as.data.frame(vegan::scores(ass.rel.t2_NMS,"species")) ## some species don't have scores
species.scores.t2$species<-rownames(species.scores.t2) 

### NMDS 1 and 2 
log<-mds_scores_t2[mds_scores_t2$treatment == "log", ][chull(mds_scores_t2[mds_scores_t2$treatment == 
                                                          "log", c("NMDS1", "NMDS2")]), ]

open<-mds_scores_t2[mds_scores_t2$treatment == "open", ][chull(mds_scores_t2[mds_scores_t2$treatment == 
                                                               "open", c("NMDS1", "NMDS2")]), ]

hulldat<-rbind(log,open)

nmds.plot <- ggplot()+
  theme_bw()+
  theme(panel.background = element_blank(),
        panel.grid.major = element_blank(),  #remove major-grid labels
        panel.grid.minor = element_blank(),  #remove minor-grid labels
        plot.background = element_blank(), 
        axis.text = element_text(size = 15),
        axis.title=element_text(size=20),
        legend.title=element_text(size=20), 
        legend.text=element_text(size=15))+
  geom_text_repel(data=species.scores.t2, aes(NMDS1, NMDS2, label=species), alpha=0.9, size=5, col='darkgray')+
  geom_polygon(data=hulldat, aes(NMDS1, NMDS2, fill=treatment, group=treatment), alpha=0.3)+scale_fill_manual(values=c("#63A088","#56638A"), name="Treatment")+
  geom_point(data=mds_scores_t2, aes(NMDS1, NMDS2, shape=block, col=treatment), size=6)+ scale_shape_manual(values = c(14,15,16,17,11,18,8), name='Block')+
  scale_colour_manual(values=c("#63A088","#56638A"), name="Treatment")+
  geom_segment(aes(x = 0, y = 0, xend = NMDS1, yend = NMDS2), 
       data = en_coord_cont, size =1, alpha = 0.5, colour = "grey30") +
     geom_text(data = en_coord_cont, aes(x = NMDS1, y = NMDS2), colour = "grey30", 
       fontface = "bold", label = row.names(en_coord_cont))
  
print(nmds.plot)
```

```{r}
# subset data where all t0 communities, insitu log and insitu open communities at t1 and t2 are included.
mat3 <- mat[which(mat$time=="t0" |  mat$treatment=="open" | mat$treatment=="insitu_log"),]
mat3$grp<-apply(mat3[c(88,89,91)], 1, paste, collapse=":") # block, init as grouping
names(mat3) #check

# another df where the grouping variables are time, block and initial state
# each row is a transect in a certain year.
df<-mat3[,c(1:87, 93)]
df2 = df %>% mutate(across(.cols=1:87,.fns=as.numeric)) # make everything numeric
rownames(df2)<-NULL # remove rownames

## new with group vars
nublock<-separate(df2, 88, c("time", "block", "init"), ":") # just looking at time, block & initial treatment

# want to sum across transects in same block X init treatment
nublock$sumgrp<-apply(mat3[c(88,89, 91)], 1, paste, collapse=":")
head(nublock)

# sum observations across initial X  block (group variable)
# this gives number of plants in each transect TYPE for each year in each block. should be 2 types X 3 years X 7 blocks rows 
blocksum<-rowsum(nublock[,c(1:87)], group=nublock$sumgrp)
blocksum$grps<-rownames(blocksum)
rownames(blocksum)<-NULL # remove rownames
nrow(blocksum) # it is 42 rows as expected 

##  expand again
blocksum<-separate(blocksum, 88, c("time", "block", "init"), ":")
nutrient_join <- nutrient[,c(1,3,5:16)]
blocksum <- inner_join(blocksum, nutrient_join, by = c("init", "block"))

# at the moment this includes where there were no plants ("x" column in matrix)
assemblies_t012<-blocksum[,c(1:87)]

# group - these are the treatment variables that need to be separately fed into the MDS analaysis from the community analysis.
group_init<-blocksum$init
group_block<-blocksum$block
group_time<-blocksum$time
group_nutrient <-blocksum[, 90:101]

# MDS 
ass.rel.t012<-decostand(assemblies_t012, method='hel') #standardize assemblies 
ass.rel.t012_NMS <- metaMDS(ass.rel.t012, distance = 'bray', k = 5) # run MDS 
stressplot(ass.rel.t012_NMS) # check fit
en.nutrient = envfit(ass.rel.t012_NMS, group_nutrient, permutations = 999, na.rm = TRUE)
# plot(ass.rel.t012_NMS) 
# plot(en.nutrient)
print(en.nutrient) ########## it is basically saying most of the nutrient does not affect the composition of plants.

# scores
mds_scores_t012<-as.data.frame(vegan::scores(ass.rel.t012_NMS)$sites) # extract scores
mds_scores_t012$site<-rownames(vegan::scores(ass.rel.t012_NMS)$sites) # extract names 
mds_scores_t012$treatment<-group_init # grouping factor 1 
mds_scores_t012$block<-group_block # grouping factor 2 
mds_scores_t012$time<-group_time # grouping factor 3
mds_scores_t012 <- cbind(mds_scores_t012, group_nutrient)
en_coord_cont = as.data.frame(vegan::scores(en.nutrient, "vectors")) * ordiArrowMul(en.nutrient)

# explaining factors
init<-as.factor(group_init) # grouping factor 1- convert to factor
block<-as.factor(group_block) # grouping factor 2- convert to factor
time<-as.factor(group_time)

#### rda model analysis & results #### 
# can look at significance of model where initial treatment and block explain variation in community
trt_tot_2<-rda(ass.rel.t012~init+block+time) # run model using standardized data 
summary(trt_tot_2)
anova.cca(trt_tot_2, step=1000, by="term") ## test for model significance

# can model using varpart to look at contributions of initial treatment and block
var.mod2<-varpart(ass.rel.t012, init, block, time) # run model on standardized data
plot(var.mod2, bg=c("hotpink","skyblue","lightyellow"))
mtext("X1= Treatment; X2=Block; X3=time", side=3)

## can test for significance of contribution of the fraction of initial treatment
# do this with partial redundancy analysis
trt_Frac<-rda(ass.rel.t012~ init +Condition(block + time)) # partial rda model
summary(trt_Frac) 
RsquareAdj(trt_Frac)$adj.r.squared #explanatory power
anova.cca(trt_Frac) ## this tells us if first condition, init, significantly contributes to overall variance explanation. 

### extracting species scores and plotting 
# species scores
species.scores<-as.data.frame(vegan::scores(ass.rel.t012_NMS,"species")) ## some species don't have scores
species.scores$species<-rownames(species.scores) 

### NMDS 1 and 2 
log<-mds_scores_t012[mds_scores_t012$treatment == "log", ][chull(mds_scores_t012[mds_scores_t012$treatment == 
                                                          "log", c("NMDS1", "NMDS2")]), ]

open<-mds_scores_t012[mds_scores_t012$treatment == "open", ][chull(mds_scores_t012[mds_scores_t012$treatment == 
                                                               "open", c("NMDS1", "NMDS2")]), ]

hulldat<-rbind(log,open)

options(ggrepel.max.overlaps = Inf)

nmds.plot <- ggplot()+
  theme_bw()+
  theme(panel.background = element_blank(),
        panel.grid.major = element_blank(),  #remove major-grid labels
        panel.grid.minor = element_blank(),  #remove minor-grid labels
        plot.background = element_blank(), 
        axis.text = element_text(size = 15),
        axis.title=element_text(size=20),
        legend.title=element_text(size=20), 
        legend.text=element_text(size=15))+
  geom_text_repel(data=species.scores, aes(NMDS1, NMDS2, label=species), alpha=0.9, size=5, col='darkgray')+
  geom_polygon(data=hulldat, aes(NMDS1, NMDS2, fill=treatment, group=treatment), alpha=0.3)+
  scale_fill_manual(values=c("#63A088","#56638A"), name="Treatment")+
  geom_point(data=mds_scores_t012, aes(NMDS1, NMDS2, shape=block, col=treatment), size=6)+ 
  scale_shape_manual(values = c(14,15,16,17,11,18,8), name='Block')+
  scale_colour_manual(values=c("#63A088","#56638A"), name="Treatment")+
  geom_segment(aes(x = 0, y = 0, xend = NMDS1, yend = NMDS2), 
       data = en_coord_cont, size =1, alpha = 0.5, colour = "grey30") +
     geom_text(data = en_coord_cont, aes(x = NMDS1, y = NMDS2), colour = "grey30", 
       fontface = "bold", label = row.names(en_coord_cont))

print(nmds.plot)
```

#### *Interpretation* 

### **Q3 Are/how are plant species performances affected by proximity to fallen logs?**<br>
#### *Overview of results* <br> 

#### *Statistical Methods* <br>

My basic approach is to analyse count and biomass data from 2021 and 2022 sowing experiment. We sowed 15 seeds for each species into 16 plots in each of the seven blocks. There are 6 plot type treatments. The gap and open treatments each have four replicates per block, and the insitu_log, insitu_pvc, open_with_log, and open_with_pvc each have two replicates per block. *note: For each treatment of plot type, there is also a dispersal treatment, but I do not analyse that here (yet).*
<br> 
- For **count data** I use a glmmTMB to run a generalized linear mixed effects model approach to analyse the data. The hurdle model approach I am using is to first code presence/absence as 0 or 1 (1 being any nonzero count value) and run this analysis as a binomial regression. Depending on the model fit and residual dispersion (using DHARMa), I then either run a truncated poisson or truncated negative binomial regression on the count data. Though I did run alternative versions of hurdle models that predict count while accounting for zero inflation, I felt that analyzing the presence/absence, and then analyzing count, may be revealing more of the biology of the system, where presence/absence was distinctly affected by treatments while count was less so.
<br>
- For **biomass data** I use linear mixed effects model to analyse the per capita biomass data. I first do a log(1+n) transformation on the per capita biomass, then analyze. I chose to do per capita biomass because of recalcitrant (!!) residual dispersion in total biomass, even after attemtps at log and square root transformations.
<br>
I chose to do a model selection approach, which I'm trying to move away from generally. However, the models I use to analyze the data represent different hypotheses about *why* plant species might perform differently, and so I chose to do a model comparison and selection approach as a way to not only understand how plant species performance is affected by proximity to fallen logs, but also gain insight as to why this may be the case. 

The models I use test the hypotheses from above: Log decomposition creates islands of fertility directly around the fallen log and fallen logs alter the microclimate directly around them by providing shade. I can also investigate using the different response variables if logs affect the presence/absence of plants, the number of plants that come up, or the biomass of the plants in the end. 

#### *Analysis*<br>

**2021**
```{r abundance code, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE, results=TRUE}

# packages 
require(lme4)
require(emmeans)
require(pscl)
require(glmmTMB)
require(tidyr)
require(DHARMa)
require(ggplot2)
require(AICcmodavg)
require(ggpubr)


############## 2021 data #############

# read csv
dat<-read.csv('nplants_data_2021_git.csv', header=T)
dat1<-dat[which(dat$seeding_trt==1),]
dat1$physical_barrier<-as.factor(dat1$physical_barrier)
dat1$block<-as.factor(dat1$block)

############# treatment response: do analysis for count by species ############# 

dat2<-(dat1[c(1:4,7,11,15,22)]) # these are block, transect, initial, current_plot_type, ngoro, ntrcy, ntror, physical_barrier
head(dat2) 

# max out at 15
countdat<-as.data.frame(dat2 %>% pivot_longer(c(ntror, ngoro, ntrcy)))
countdat$value<-as.numeric(ifelse(countdat$value>15, 15, countdat$value))

#### now i'll do a by-hand hurdle model on my own using a truncated negative binomial

### zeros and ones 
countdat$presence<-ifelse(countdat$value==0, 0, 1)
zerofit<-glmmTMB(presence~name*current_plot_type+(1 | block), family=binomial, data=countdat, REML=FALSE)
emmip(zerofit,~current_plot_type|name, type='response',CI=T)
est<-emmeans(zerofit, ~current_plot_type|name, type='response')
pairs(est)

### abundance with a truncated negbinom 
countdat$posicounts<-as.numeric(ifelse(countdat$value==0, "NA", countdat$value))
countfit<-glmmTMB(posicounts~name*current_plot_type+(1 | block), family=truncated_nbinom2(), data=countdat, REML=FALSE)
emmip(countfit,~current_plot_type|name, type='response',CI=T)
est<-emmeans(countfit, ~current_plot_type|name, type='response')
pairs(est)

#### *Interpretation* 